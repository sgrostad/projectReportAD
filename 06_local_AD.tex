\chapter{Local Automatic Differentiation}
\label{ch:LocalAD}
This chapter will consider a different approach on how to use AD to solve PDEs. When solving PDEs using a finite element method each cell will only depend on the neighbouring cells. In the \texttt{FAD} and \texttt{CJAD} implementations, the dependencies are stored in the discrete gradient and divergence operators. The implementation of \texttt{FAD} and \texttt{CJAD} calculates the residual function value and corresponding Jacobian for the whole grid simultaneously by having a vector to store the values and sparse matrices for the Jacobians. Hence when the discrete gradient and divergence operators are used in the calculation of the residual function in \autoref{ch:FlowSolver}, the Jacobian are automatically obtained with the structure seen in \autoref{fig:flowSolverJacobian}. However, this structure is known from the grid properties given in the \texttt{G} variable introduced in \autoref{sec:GridConstruction}. So instead of calculating the residual function for all cells at once, the new approach takes one cell at the time and sums up the contributions from each neighbour. This is done for each cell until all the residual functions for each cell is calculated. This new approach is called local AD and the method is based on the same idea as how AD is done in OPM \emph{\citep{OPM}}. Since OPM is written in C and C++ it is interesting to see if you can write similar type of code in Julia and obtain the same computational efficiency. \todo{Må teste noe mot dette og kommentere for at dette skal kunne stå der}

\section{Implementation}
To get a better understanding of how Local AD works, it is best to look at how it is implemented. Like for \texttt{FAD} and \texttt{CJAD} I have implemented local AD using a struct I have called \texttt{LAD}:
\lstinputlisting{code/LAD_structSimple.jl}
Since we now only operate on one cell at the time the implementation of local AD is simpler than for \texttt{FAD} and \texttt{CJAD}. The value of the AD-variable is now only a scalar and the Jacobian matrices is replaced by a vector of derivatives. These are the derivatives  with respect to the primary variables in the cell. To easily create a new \texttt{LAD} primary variable with a given number of derivatives and where the derivative with respect to itself is $1.0$, I have created a function called \texttt{createVariable}:
\lstinputlisting{code/createVariable.jl}
For the single phase flow solver in \autoref{ch:FlowSolver}, the derivatives vector will be of length one, as each cell only contain one primary variable (pressure). The implementation of \texttt{LAD} is however with \texttt{derivatives} as a vector. This is for the opportunity to implement more complex simulations like a two or three phase simulation where each cell can contain water, oil and/or gas \todo{legg til referanse her om to-fase simulering blir vellykket}. The implementation of operators for the \texttt{LAD} struct is done similar as explained in \autoref{ch:Implementation} for \texttt{FAD} and \texttt{CJAD}, but since we only have a vector of derivatives instead of a Jacobian matrix, the implementation is easier and follows the lines of the description from \autoref{sec:FADWithMultipleParameters}. 

Where the implementation of the local AD tool is easier than for \texttt{FAD} and \texttt{CJAD}, there is more work when creating the simulation. Since we do not use discrete gradient and divergence operators, but traverse through the grid cell by cell, we need somewhere to store the resulting values of the residual function. We also need a method to traverse through all the cells and to calculate the contributions from each neighbouring cell. Where the AD part of the code in \texttt{FAD} and \texttt{CJAD} were fully separated from the simulation, for local AD it is more integrated. This means that when using local AD to create the simulation it becomes a more application specific implementation than the method for \texttt{FAD} and \texttt{CJAD}. To create the flow solver from \autoref{ch:FlowSolver} I have chosen to store the calculated values of the residual functions in another struct called \texttt{FlowSystem}:
\lstinputlisting{code/FlowSystem.jl}
This struct look very similar to the other AD structs, except from \texttt{globalJac} being one single sparse matrix instead of a vector of sparse matrices and each element in \texttt{globalJac} being a vector. At this point you might not understand why it is quicker to calculate the residuals cell by cell compared to everything in one go. The key reason for this is that we know that the structure of the global Jacobian will stay the same throughout the whole simulation. This means we can use the grid variable \texttt{G}, that contains the information on which cells are neighbours, and build the correct structure of \texttt{globalJac} once and for all. When we run the simulation we only change the values inside of \texttt{globalJac}, but the structure stays the same. This reuse of \texttt{globalJac} will save a lot of memory allocations and hence speed compared to \texttt{FAD} and \texttt{CJAD} which allocates new structs for each calculation. By creating a new constructor for \texttt{FlowSystem} that uses the grid variable \texttt{G}, the variables \texttt{eqVal} and \texttt{globalJac} will be allocated with the correct length and the correct structure before the simulation begins. For the grid in \autoref{ch:FlowSolver} we have 1000 cells. This implies 1000 different pressure values and in addition we have the bottom-hole pressure (\texttt{bhp}) and the total production (\texttt{qS}). Hence \texttt{eqVal} will be a vector of length 1002.

Now that \texttt{FlowSystem} stores the  values and Jacobian of the residual functions, we need a new function to traverse through all cells and performing the residual calculations. I have chosen to call this function \texttt{assembleFlowSystem!()} where the exclamation mark is a Julia convention for a function that modifies its input parameters. The code for \texttt{assembleFlowSystem!()} can be seen below. I have for brevity removed all declarations of help variables and replaced the code for evaluation of the residual functions and the updating of \texttt{FlowSystem} with comments.
\lstset{numbers=left}
\lstinputlisting{code/assembleFlowSystem!.jl}
\lstset{numbers=none}
\texttt{assembleFlowSystem!()} first resets \texttt{eqVal} and \texttt{GlobalJac} such that the structures are unchanged, but all the values are zero. Then the function begin traversing through the grid and for every cell it iterates through all neighbouring cells. The \texttt{eqVal} and \texttt{globalJac} variables in the \texttt{FlowSystem} struct is updated in line number 6, 8 and 10 inside the inner loop. As a reminder, the residual functions that \texttt{FlowSystem} eventually will represent are the functions \texttt{presEq}, \texttt{rateEq} and \texttt{ctrlEq} defined in \autoref{sec:setupGovEq}:
\lstinputlisting{code/governingEquationsPresSolver.jl}


In line number 6, when \texttt{fromCell} and \texttt{toCell} are equal, the first term in the sum in \texttt{presEq}, or the backward Euler term, is calculated. This is performed in an outer function \texttt{timeDerivative} that returns a \texttt{LAD} struct:
\lstinputlisting{code/timeDerivative.jl}
In \texttt{FAD} and \texttt{CJAD} we made all the primary AD-variables before the simulation and used them as input parameters in the residual functions. These functions returned new AD-variables that represented the values and Jacobians of the residual functions. With local AD we create new primary AD-variables for the specific cell inside the residual functions when we need them to calculate function values and derivatives. When \texttt{timeDerivative} have returned a \texttt{LAD} variable, \texttt{assembleFlowSystem!()} add the calculated value to the correct index in \texttt{FlowSystem.eqVal} and the derivative vector to the correct diagonal index in \texttt{FlowSystem.globalJac}.

\todo[inline]{Se på parallellisering for lokal AD?}