\chapter{Local Automatic Differentiation}
\label{ch:LocalAD}
This chapter will consider a different approach on how to use AD to solve PDEs. When solving PDEs using a finite volume method each cell will only depend on the neighbouring cells. In the \texttt{FAD} and \texttt{CJAD} implementations, the dependencies are stored in the discrete gradient and divergence operators. The implementations calculate the residual function value and corresponding Jacobian for the whole grid simultaneously by having a vector to store the values and sparse matrices for the Jacobians. Hence, when the discrete gradient and divergence operators are used in the calculation of the residual function in \autoref{ch:FlowSolver}, the Jacobian are obtained with the structure seen in \autoref{fig:flowSolverJacobian}. Local AD is an alternative approach that instead of calculating the residual function for all cells at once, using matrix and vector operations, iterates through the grid and for each cell calculates the local residual. In the end it will perform exactly the same calculations as \texttt{FAD} and \texttt{CJAD}, but instead of having large vector and matrix calculations, we now have smaller calculations concerning only one cell, and its neighbours, at the time. This new approach is based on the same idea as how AD is implemented in OPM \emph{\citep{OPM}}, which, as said in \autoref{ch:FlowSolver}, is written in C and C++ and scales better when the simulations become larger. It is hence interesting to see if you can write similar type of code in Julia and obtain better computational efficiency than what is achieved in MATLAB with MRST, as well as with the methods I have implemented in Julia.

\section{Implementation}
\label{sec:LADImplementation}
To get a better understanding of how local AD works, it is best to look at how it is implemented\footnote{In the following I will explain a minor simplified implementation. This is to keep the focus on the essential parts of the implementation. The left out parts will be discussed in \autoref{sec:optimizingLocalAD}}. Like for \texttt{FAD} and \texttt{CJAD} I have implemented local AD using a struct called \texttt{LAD}:
\lstinputlisting{code/LAD_structSimple.jl}
Since we now only operate on one cell at the time, the implementation of local AD is simpler than for \texttt{FAD} and \texttt{CJAD}. The value of the AD-variable is now only a scalar and the Jacobian matrices are replaced by a vector of derivatives. These are the derivatives  with respect to the primary variables in the cell. For the single-phase flow solver in \autoref{ch:FlowSolver}, the derivatives vector will be of length one, as each cell only contains one primary variable (pressure). The implementation of \texttt{LAD} is, however, with \texttt{derivatives} as a vector. This is for the opportunity to implement more complex simulations like a two- or three-phase simulator, where each cell can contain multiple primary variables for the amount of water, oil and/or gas present in the cell (an example of a two-phase simulator can be seen in \autoref{sec:TwoPhaseSimulation}).

To make sure that each primary variable is initialized correctly, initialization of \texttt{LAD} variables is done with the \texttt{createVariable} function. This function creates a \texttt{LAD} variable with a value and a given number of derivatives. The derivative with respect to itself is set to $1.0$, whereas the other derivatives are zero.
\lstinputlisting{code/createVariable.jl}
The operators for the \texttt{LAD} struct are implemented similarly as explained in \autoref{ch:Implementation} for \texttt{FAD} and \texttt{CJAD}, but since we now, instead of having a Jacobian matrix, only have a vector of derivatives, the implementation is easier and follows the lines of the description from \autoref{sec:FADWithMultipleParameters}. 

Whereas the implementation of the local AD tool is easier than for \texttt{FAD} and \texttt{CJAD}, there is more work when calculating the residual functions. Since we no longer can use discrete gradient and divergence operators, but instead have to traverse through the grid cell by cell, we need a place to store the resulting residual values and the corresponding Jacobian. We also need a method to traverse through all the cells and calculate the contributions from each neighbouring cell. %Where the AD part of the code in \texttt{FAD} and \texttt{CJAD} were fully separated from the simulation, for local AD it is more integrated. This means that when using local AD to create the simulation it becomes a more application specific implementation than the method for \texttt{FAD} and \texttt{CJAD}. 
To create the flow solver from \autoref{ch:FlowSolver}, I have chosen to store the calculated values of the residual functions in another struct called \texttt{FlowSystem}:
\lstinputlisting{code/FlowSystem.jl}
This struct looks very similar to the other AD structs, except from \texttt{globalJac} being one single sparse matrix instead of a vector of sparse matrices. At this point you might not understand why it is quicker to calculate the residuals cell by cell compared to everything in one go. The key reason for this lies in the \texttt{FlowSystem} struct. Since we know that the structure of the global Jacobian will stay the same, we can reuse this sparse matrix structure throughout the whole simulation. Before the simulation begins, we use the grid variable \texttt{G}, which contains the information on which cells are neighbours, and build the correct structure of \texttt{globalJac} once and for all. When we later run the simulation, we only change the values inside of \texttt{globalJac}, but the structure stays the same. This reuse of \texttt{globalJac} will save a lot of memory allocations and hence consume less CPU time compared to \texttt{FAD} and \texttt{CJAD}, which both allocate new structs for each calculation. By creating a new constructor for \texttt{FlowSystem} that uses the grid variable \texttt{G}, the variables \texttt{eqVal} and \texttt{globalJac} will be allocated with the correct length and the correct structure before the simulation begins. For the grid in \autoref{ch:FlowSolver}, we have 1000 cells. This implies 1000 different pressure values and in addition we have the bottom-hole pressure (\texttt{bhp}) and the total production (\texttt{qS}). Hence, \texttt{eqVal} will be a vector of length 1002.

Now that \texttt{FlowSystem} stores the  values and Jacobian of the residual functions, we need a new function to traverse through all cells and perform the calculations. The function that will execute the calculations is \texttt{assembleFlowSystem!()}, where the exclamation mark is a Julia convention for a function that modifies its input parameters. The corresponding code can be seen below. I have removed all declarations of help variables and replaced the code for updating \texttt{FlowSystem} with comments to highlight the important parts of the function structure. What I have not mentioned previously is that \texttt{FlowSystem} will contain an extra vector containing the current pressure. Since we use the pressure to calculate the residual functions, it is natural to store the current pressure next to the residual values
\lstset{numbers=left}
\lstinputlisting{code/assembleFlowSystem!.jl}
\lstset{numbers=none}
The input parameter \texttt{well} is a struct that contains all necessary information about the well. What I have not mentioned previously, is that \texttt{FlowSystem} will also contain an extra vector containing the current pressure. Since we use the pressure to calculate the residual functions, it is natural to store the current pressure next to the residual values. This is why there is only the pressure at the previous time step, \texttt{P0}, in addition to \texttt{fs} and \texttt{well}, as an input parameter. The first line in \texttt{assembleFlowSystem!()} resets \texttt{eqVal} and \texttt{GlobalJac} such that the structures are unchanged, but all the values are set to zero. Then, the function starts traversing through the grid and for every cell it adds up the contributions from all neighbouring cells. Be aware that the looping variable names \texttt{fromCell} and \texttt{toCell} can be a bit misleading when they represent bottom-hole-pressure and total production, as those primary variables do not belong to any cell. The intuitiveness of considering the flow from one cell to another is however considered more valuable than the issue that they will also represent bottom-hole-pressure and total production. The \texttt{eqVal} and \texttt{globalJac} variables are updated in line number 6, 8 and 10 inside the inner loop. As a reminder, the residual functions that \texttt{FlowSystem} eventually will represent are the functions \texttt{presEq}, \texttt{rateEq} and \texttt{ctrlEq} defined in \autoref{sec:setupGovEq}:
\lstinputlisting{code/governingEquationsPresSolver.jl}
In line number 6, \texttt{fromCell} and \texttt{toCell} are equal, but do not reference the bottom-hole-pressure or total production. Here, the first term in \texttt{presEq}, or the backward Euler term, is calculated. This is performed in an outer function called \texttt{timeDerivative()} that returns a \texttt{LAD} struct:
\lstinputlisting{code/timeDerivative.jl}
In \texttt{FAD} and \texttt{CJAD}, we made all the primary AD-variables before the simulation. We then used them as input parameters in the residual functions that returned new AD-variables which represented the values and Jacobians. With local AD, we create new primary AD-variables for the applicable cell inside the function we want to evaluate. For \texttt{timeDerivative()} we create a \texttt{LAD} primary variable that represents the pressure in the cell before we calculate the backward Euler term. When \texttt{timeDerivative()} has returned the new \texttt{LAD} variable, \texttt{assembleFlowSystem!()} adds the calculated value to the correct index in \texttt{eqVal} and the derivative value to the correct diagonal index in \texttt{globalJac}.

In line number 10, when \texttt{fromCell} and \texttt{toCell} are two neighbouring cells, the divergence term in \texttt{presEq} is calculated. Like for \texttt{timeDerivative()}, we create the primary AD-variables inside the function, but since we calculate the flux from one cell to another, we have to be careful with which direction we calculate the flux and which cell we want the derivative with respect to. Since the varying variables are named \texttt{fromCell} and \texttt{toCell}, it is natural that the function \texttt{flux()}, seen below, calculates the flux from \texttt{fromCell} to \texttt{toCell}. 
\lstinputlisting{code/fluxFunctionLocalAD.jl}
What needs to be chosen is which cell we want the derivative with respect to. The choice only affects which indices of the Jacobian the calculated derivatives should be added or subtracted to. In \texttt{flux()}, I have decided to calculate the derivative with respect to \texttt{fromCell}. The two first lines show the consequence of this, where \texttt{pFrom} is initialized with a derivative of $1$ and \texttt{pTo} as a constant. This choice leads to the following code for updating \texttt{FlowSystem} at line number 10 in \texttt{assembleFlowSystem!()}:
\lstinputlisting{code/fluxCodeLocalAD.jl}
The value of \texttt{fluxLAD} is added to \texttt{eqVal} and the derivative of the flux with respect to \texttt{fromCell} is added to \texttt{globalJac}. In addition we know that the flux from \texttt{fromCell} to \texttt{toCell} is the same as from \texttt{toCell} to \texttt{fromCell}, but with negative sign. This means that the derivative of the flux from \texttt{toCell} with respect to \texttt{fromCell} needs to be subtracted with \texttt{fluxLad.derivatives}. For a facet between two neighbours, we will with \texttt{assembleFlowSystem!()} calculate the value of the flux through the facet twice, only with different signs. You might think that we could save time by subtracting \texttt{fs.eqVal[toCell]} with \texttt{fluxLAD.val}, but since we also will need the opposite derivatives of this particular flux, there will small, or next to none, computational gain of exploiting this fact. In worst case it might actually become a slower implementation, as we would have had to keep track of which fluxes had been added to which cells. When the fluxes from all the neighbours have been added up for a cell, we have obtained the divergence in that cell. 

Line number 8 in \texttt{assembleFlowSystem!()} is the last line I have not commented and it is where the well equations, \texttt{rateEq} and \texttt{ctrlEq}, are handled. This line is executed if both \texttt{fromCell} and \texttt{toCell} either refer to one of the cells containing a well, the bottom-hole pressure, or the total production. The information on which cells fulfilling this condition lies in \texttt{well}. The calculation is performed by handling every case such that the correct residual functions, namely the \texttt{rateEq} or the \texttt{ctrlEq}, are calculated and added to the correct indices in \texttt{FlowSystem}.

Summed up, the calculation of the residual functions using local AD is based on two modules. The first is the actual AD tool with the \texttt{LAD} struct, and the second is \texttt{FlowSystem}, which keeps track of the global system and what calculations should be performed by the AD tool. With this approach, we loose some of the advantages using the other AD tools where the discrete residual functions looked very similar to the continuous case, like explained in \autoref{sec:setupGovEq}. The main structure of \texttt{assembleFlowSystem!()} will, however, be the same no matter what type of simulation, hence making modifications to the code, or building another simulator, will not demand a complete change of the code structure.

Now that the assemble of the governing equations are implemented, we need a main loop that performs the simulation. The good news is that this main loop will be very similar to the one outlined in \autoref{sec:setupGovEq}. The only difference is that instead of evaluating a residual function F, we assemble the equations using \texttt{assembleFlowSystem!()}. A pseudo code of the new main loop can be seen below. 
\lstinputlisting{code/FlowSimulatorLocalAD.jl}

\section{Optimizing Local AD}
\label{sec:optimizingLocalAD}
As explained in the beginning of this chapter, the main idea behind local AD is to reuse the Jacobian to save memory usage and extra memory allocations. The implementation given in \autoref{sec:LADImplementation} has nevertheless left out some small, but key parts of the implementation that will massively decrease the memory and CPU usage. This is purely implementation specific differences that have been left out to make the introduction to local AD more clear. It will not change the theory behind using local AD to solve PDE's.

\subsection{Dynamic VS Static Arrays}
The difference between a dynamic array and a static array is that a dynamic array can be extended or shortened as much as you like while a static array has a fixed length. Using a static array will give computational gain concerning speed and memory allocations compared to a dynamic array. This is because the compiler knows that a static array has the given fixed length forever and hence it can allocate the exact memory needed in advance and optimize the machine code accordingly. With a dynamic array, the compiler does not know if the array will grow larger, or smaller, and it is much harder to optimize the machine code. 

Julia has a package called \emph{\cite{StaticArrays}} that provides static arrays with the same abilities as the built-in arrays, but without the possibility for changing the size of the array. The package provides two types of vectors, \texttt{SVector} and \texttt{MVector}(for two-dimensional arrays it has the corresponding \texttt{SMatrix} and \texttt{MMatrix}). Both are static vectors, but \texttt{MVector} is mutable, meaning the values inside the vector can be changed, whereas the values inside an \texttt{SVector} are final once the vector is defined. This makes \texttt{SVector} ideal for \texttt{LAD.derivatives}, since when we perform operations on \texttt{LAD} variables, new \texttt{LAD} variables are returned.\footnote{For a multiphase simulation, a possible implementation can be each element in the global Jacobian being an \texttt{n}$\times$\texttt{n} matrix, where \texttt{n} is the number of primary variables in each cell. For this particular case, an \texttt{MMatrix} is optimal to use as we know the size of the matrices, but we want to change the values inside the matrix.} 

When the implementation is changed to use static vectors, it needs to know how long these vectors are. When building a simulator, it is not a problem to say in advance how many derivatives we need, and once the compiler knows this before compilation, it can optimize the machine code. OPM solves this by creating a template class containing the length of the gradient vector.\todo{Legg til både kilde og sjekk formulering} This ensures that the compiler always knows that for this simulator, the static vector will always have this fixed length. This is important because we do not want to create \texttt{LAD} structs with different lengths for \texttt{LAD.derivatives}. In addition, if we define this clearly, the compiler knows exactly how much memory is needed when we allocate a new \texttt{LAD} variable. By giving the compiler this information before compilation, we help the it to optimize the machine code. This will also make the implementation of the operators of \texttt{LAD} easier, as we know for certain that all \texttt{LAD} variables will have \texttt{derivatives} vectors with the same length. The best implementation I have found for this in Julia is to declare a global constant variable in the local AD module such that the new implementation of \texttt{LAD} becomes:
\lstinputlisting{code/LAD_struct.jl}
One disadvantage with this implementation is that the Local AD module needs to be modified to work for simulations with more primary variables for each cell. \todo{Må se om det finnes noen annen måte, hvis ikke bør det kanskje kommenteres at det er litt krøkkete}

\section{Flow Solver with Local AD}
\label{sec:flowSolverWithLAD}
Now that \texttt{LAD} has been implemented with static vectors, it is interesting to see how the local AD method compares to \texttt{FAD} and \texttt{CJAD} in the simulation from \autoref{ch:FlowSolver}. Since the local AD technique from OPM, unlike the vectorized methods from MRST, is constructed with a main focus on computational efficiency, and since it is also assumed that Julia is supposed to run as fast as C, we expect that the local AD approach will give significant computational gain. This is unfortunately not the case with the implementation outlined in this chapter. Indeed, \texttt{LAD} performs worse than \texttt{CJAD} and similar to \texttt{FAD}. 

As explained in \autoref{sec:profiling}, profiling is an efficient way of finding the bottlenecks in a code, and this is a perfect example of when to use it - the code was expected to be faster, but it was not, so it is important to figure out if there is a small part of the code that is slow. \autoref{fig:profileSlowCreateVar} shows a screenshot of a profile result from running the flow solver simulation. The screenshot only contains blocks from the \texttt{flux()} function. Two blocks are marked with squares and two other blocks with brighter diagonal stripes. The blocks with squares are time spent in \texttt{createVariable()} and the brighter diagonal stripes are AD calculations in \texttt{flux()}.
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.75\textwidth}
        \includegraphics[height = 0.35\textheight, width=\textwidth ]{figures/profilingSlowCreateVariablesFlux.png}
        \caption{}
        \label{fig:profileSlowCreateVar}
    \end{subfigure}
    \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.18\textwidth}
        \includegraphics[height = 0.35\textheight, width=\textwidth]{figures/profilingFastCreateVariablesFlux.png}
        \caption{}
        \label{fig:profileFastCreateVar}
    \end{subfigure}
    \caption{The figures shows screenshots of the profile result from \texttt{flux()} in the flow solver simulation from \autoref{ch:FlowSolver}. The blocks marked with squares are time spent in \texttt{createVariable()} and the blocks with bright diagonal lines are calculations in \texttt{flux()}. \autoref{fig:profileSlowCreateVar} uses a slow version of \texttt{createVariable()} while \autoref{fig:profileFastCreateVar} uses a faster version.}
\end{figure}
It is suprising that creating a \texttt{LAD} struct should take more time than the actual AD calculations. This indicates that the \texttt{createVariable()} function is poorly implemented. If we look closer at the implementation, we see that we only want to create a static \texttt{Svector}, but we start by creating a dynamic vector of zeros, and then we modify the vector by changing one of the values to one. Finally, we convert the dynamic vector into a static \texttt{SVector} in the last line. The new implementation seen below is a Julia specific implementation, where the \texttt{SVector} is created immediately with correct values and without any use of dynamic vectors.
\lstinputlisting{code/createVariableFast.jl}
The new profiling result with the updated \texttt{createVariable()} can be seen in \autoref{fig:profileFastCreateVar}. The time spent in \texttt{createVariable()} is almost eliminated and we can see that approximately all the time spent in \texttt{flux} is used for AD calculations. This is what is expected as initialization should be far less time consuming than AD calculations. 

As discussed in \autoref{ch:FlowSolver}, by only looking at assembling of the residual functions, and not the full simulation, we eliminate the linear solver from the benchmark, and we get a better understanding of how efficient the AD tools are. \autoref{tab:FlowSolverAssemblyTestWithLAD} is the same table as \autoref{tab:FlowSolverAssemblyTest}, assembling the residual functions 100 times, but with the benchmarked time for Local AD added to the end of the table.
\begin{table}[htb]
    \centering
    \caption{Table with speed benchmarks of different AD methods assembling the "Single-Phase Compressible AD Solver" residual function 100 times for different discretizations.}
    \label{tab:FlowSolverAssemblyTestWithLAD}
    \def\arraystretch{1.5}
    \begin{tabular}{ccccc}
    \textbf{Number of cells} & \textbf{FAD} & \textbf{CJAD} & \textbf{MRST} & \textbf{Local AD}\\
        \hline
         $10\times10\times10$ & 0.9s & 0.4s & 0.6s & 0.07s \\  
         $20\times20\times20$ & 9.3s & 4.0s & 3.6s & 0.6s \\ 
         $30\times30\times30$ & 44.2s& 17.2s& 16.5s & 2.2s \\ \hline
    \end{tabular}
\end{table}
The table shows that the local AD approach is approximately six times faster than the other tested implementations, which is a significant improvement. This gives us an indication that Julia can be a language where we can quickly create new simulators using the high-level and user-friendly \texttt{CJAD} or a similar AD tool, and in the same language create more efficient simulators using a method like local AD. To confirm this, however, we need to test the performance for a larger problem than a single-phase pressure solver. In \autoref{sec:TwoPhaseSimulation}, I will test how local AD performs in Julia solving a two-phase problem with a more realistic grid structure. This will give a better indication on how well Julia is suited for creating high performance simulators.

\section{Two Phase Incompressible Flow}
\label{sec:TwoPhaseSimulation}
Previously in this thesis I have only looked at single-phase flow, where the fluid present is oil. As explained in the introduction, only about 30\% of the oil in the reservoir will be extracted unless we create external forces to the reservoir. This normally consist of injecting either water, gas, or both, into the reservoir. As the purpose of this thesis is not oil recovery, but to see how the AD tools perform simulating oil recovery, I will not go deep into the physics of how it is done. More specific information about oil recovery can be found in \citet{lieMrstUrl}. Sufficient information for this example is that we want to simulate how water flows from an injector into a reservoir full of oil. This will be done for a grid from the 10th SPE Comparative Solution Project \emph{\citep{SPE10}}. This is a realistic grid created to benchmark simulators against each other.

The SPE10 (model 2) grid is split into 85 layers. Each layer contains 60$\times$220 cells, making the total number of grid cells 1 122 000. To simplify the implementation I will only look at a single layer, layer 5, making the problem two-dimensional with 13 200 cells. In differ from the grid in \autoref{ch:FlowSolver} the permeability and porosity varies throughout the grid. This will affect the path of the water flow. \autoref{fig:porositySPE10} shows the porosity in the grid and \autoref{fig:permeabilitySPE10} shows a logarithmic color plot of the permeability. Both figures also display the placement of the water injector in the center of the grid, and the four wells in each corner. \autoref{fig:porositySPE10} shows that the rock around well 3 and 4 are very dense and \autoref{fig:permeabilitySPE10} naturally shows that the permeability here is low as well. This gives us an expectation that the water will flow to the left.
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth]{figures/porositySPE10.eps}
    \caption{}
    \label{fig:porositySPE10}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth]{figures/permeabilitySPE10.eps}
    \caption{}
    \label{fig:permeabilitySPE10}
\end{figure}
\todo[inline]{Fjerne hvite kanter}
The governing equations for a two-phase flow are similar to the ones expressed in \autoref{ch:FlowSolver}, however with some changes. I will also make some simplifications to the model that I will note in the following derivation of the new governing equations. Darcy's law, expressing the flux between two cells are given in \myeqref{eq:pressSolverDarcy}, but since our grid only has one layer, we neglect the gravity Darcy's law becomes
\begin{equation*}
    \textbf{v} = - \frac{K}{\mu}\nabla p.
    \label{eq:DarcyNoGravity}
\end{equation*}
However, now we need to separate between flux of water, flux of oil and the sum of them, total flux. Before injection of water, each cell is filled with pure oil. This implies that the amount of oil in a cell equals the pore volume in that cell. The pore volume is found by multiplying the total volume of the cell with the porosity, a number between zero and one. The amount of water and oil in a cell, called the saturation, is measured similarly as the porosity with the condition
\begin{equation*}
\sum_\alpha S_\alpha = 1.
\end{equation*}
In this two phase situation $\alpha$ can be either $o$ for oil or $w$ for water. As an example, in a cell without water, the oil saturation will be $S_o = 1$ and water saturation $S_w = 0$.  Since the permeability of a cell depends on the fluid flowing through the cell, we cannot find the specific flux by simply multiplying with the saturation. To handle this we introduce the property relative permeability. Relative permeability is usually represented as an analytic function, and I have chosen to use the simplest approximation given by
\begin{equation*}
k_{r\alpha} = S_\alpha^2,
\end{equation*}
for both water and oil. The flux for a given phase is then given by the modified Darcy's law
\begin{equation*}
\textbf{v}_\alpha = - \frac{Kk_{r\alpha}}{\mu_\alpha}\nabla p_\alpha = -K\lambda_\alpha\nabla p_\alpha.
\end{equation*}
$p_\alpha$ is the pressure for the given phase and $\lambda_\alpha$ is called the mobility of phase $\alpha$. The difference between the oil pressure and the water pressure is given by the capillary pressure, $p_c = p_o - p_w$. For oil and water, the capillary pressure would cause the water to rise in the reservoir. However, in this model we neglect capillary pressure and the pressure in the oil and the water is considered to be equal. Now that we have an expression for the phase flux we obtain the conservation equation for each phase:
\begin{equation}
    \frac{\partial}{\partial t}(\phi \rho_\alpha S_\alpha) + \nabla\cdot(\rho_\alpha\textbf{v}_\alpha) = \rho_\alpha q_\alpha.
    \label{eq:continuityEqMultiPhase}
\end{equation}
If you remove $\alpha$ from \myeqref{eq:continuityEqMultiPhase}, it becomes the same equation as \myeqref{eq:continuityEqPressure}, except that here we have taken $\rho$ outside of $q$. In our two phase example we assume both phases to be incompressible such that the governing equations are given by
\begin{equation}
    \frac{\partial}{\partial t}(\phi S_\alpha) + \nabla\cdot\textbf{v}_\alpha =  q_\alpha, \hspace{1em} \alpha \in o, w.
    \label{eq:continuityEqsMultiPhaseIncomp}
\end{equation}
Since $S_o = 1 - S_w$, the equations from \myeqref{eq:continuityEqsMultiPhaseIncomp} contain two unknown variables, the saturation, for either water or oil, and the pressure. Firstly we want to obtain an equation for the pressure. By adding the two equations from \myeqref{eq:continuityEqsMultiPhaseIncomp} we obtain
\begin{equation*}
    \phi \frac{\partial}{\partial t}(S_o + S_w) + \nabla\cdot(\textbf{v}_o + \textbf{v}_w) = q_o + q_w.
\end{equation*}
Since $S_o + S_w = 1$, we can remove the time dependent term, and by defining the total flux as
\begin{equation*}
    \textbf{v} = \textbf{v}_o + \textbf{v}_w = -K\lambda_o\nabla p -K\lambda_w\nabla p = -K\lambda\nabla p,
\end{equation*}
and the total source term as $q = q_o + q_w$, we obtain the pressure equation
\begin{equation*}
    -\nabla\cdot(K\lambda\nabla p) = q.
\end{equation*}
Next we want to derive an equation for the water saturation. \myeqref{eq:continuityEqsMultiPhaseIncomp} with $\alpha = w$ gives one formulation, but we want an expression that depend on the total flux, and not the water flux. The reason for this will be explained later. To find a relation between the water flux and the total flux, observe that the difference between the waterflux multiplied with the mobility of oil and the oil flux multiplied with the mobility of water is equal to zero.
\begin{align*}
    \lambda_o\textbf{v}_w - \lambda_w \textbf{v}_o = \lambda\textbf{v}_w - \lambda_w\textbf{v} &= (\lambda_o + \lambda_w)\textbf{v}_w - \lambda_w(\textbf{v}_o + \textbf{v}_w) \\
    &= \left(\lambda_o\lambda_w + \lambda_w^2 - (\lambda_o\lambda_w + \lambda_w^2)\right)\left(-K\nabla p\right)\\
    &= 0
\end{align*}
This gives us the relation 
\begin{equation*}
    \textbf{v}_w = \frac{\lambda_w}{\lambda_o + \lambda_w}\textbf{v} = f_w\textbf{v},
\end{equation*}
where $f_w$ is called the fractional water flow.
\begin{figure}
    \centering
    \includegraphics[width = \textwidth]{figures/waterSaturation4x1ThreeYears.eps}
    \caption{\todo[inline]{Gjøre plottene større og med mindre svarte kanter}}
    \label{fig:waterSatResultsSPE10}
\end{figure}


\begin{table}[htb]
    \centering
    \caption{Write caption}
    \label{tab:FlowSolverAssemblyTestWithLAD}
    \def\arraystretch{1.5}
    \begin{tabular}{ccc}
    \textbf{Local AD} & \textbf{CJAD} & \textbf{MRST}\\
        \hline
        5.89s & 31.97s & 30.15s \\  
        \hline
    \end{tabular}
\end{table}


\todo[inline]{Se på parallellisering for lokal AD?}