\chapter{Drafts}
\section{Shared Libraries vs Static Libraries}
The difference between shared libraries and static libraries is how they handle their dependencies. When static libraries are compiled, all the code that is needed for the functions in the library is compiled into the library. This means that all the code that is needed for the library to function properly is "copied" to where it is needed. Shared libraries on the other hand has a reference to its dependencies. This will ad an extra cost to the execution since the code need to look up where the code it is supposed to run lies. The advantage of this compared to Static libraries is that the size of the library becomes smaller as we avoid replicates of code.

\section{Profiling}
Profiling is an effective method to obtain overview of where the bottlenecks lie in a code when trying to optimize its performance. The method consist of taking snapshots of the code with small time intervals and for each snapshot we register what function we are at and the functions that have called this function. In this way we obtain a register of how many times we have observed that we have been in every function. This will not give a perfect overview of how much time we spend in each function, and we even risk not registering all functions we use. But as the time interval between the snapshots are small (e.g. every tenth microsecond), a function that is not registered will not be interesting to optimize as it already is very fast. 

\section{Vectorization vs Non-vectorization}
\emph{\citep{Vectorization}} explains how Julia is faster at executing devectorized code compared to vectorized code.

\emph{\citep{MoreDotsJuliaBlog}}
Ordinary vectorized code is fast, but not as fast as a hand-written loop (assuming loops are efficiently compiled, as in Julia) because each vectorized operation generates a new temporary array and executes a separate loop, leading to a lot of overhead when multiple vectorized operations are combined.

\section{Julia}
\todo[inline]{finne et naturlig sted for dette. Kanskje i intro, eventuelt rett etter?}
\label{sec:Julia}
Julia is a new programming language that was created by Jeff Bezanson, Alan Edelman, Stefan Karpinski and Viral B. Shah at Massachusetts Institute of Technology (MIT) \citep{juliaLab}. The language was created in 2009, but was first released publicly in 2012. In 2012 \cite{juliaBlogRelease2012} said in a blog post:
\begin{quotation}
"We want a language that’s open source, with a liberal license. We want the speed of C with the dynamism of Ruby. We want a language that’s homoiconic, with true macros like Lisp, but with obvious, familiar mathematical notation like Matlab. We want something as usable for general programming as Python, as easy for statistics as R, as natural for string processing as Perl, as powerful for linear algebra as Matlab, as good at gluing programs together as the shell. Something that is dirt simple to learn, yet keeps the most serious hackers happy. We want it interactive and we want it compiled. (Did we mention it should be as fast as C?)"
\end{quotation}
To understand why the creators of Julia wanted to build this new program, we need to have a closer look at what type of programming languages are already out there, and what separates them. All programming languages that are used in numerical applications are written in a high level language. This is a language that is easily readable for a human. The code that is written is called source code. This source code needs to be translated for the machine to understand it. The translated code is called machine code. How this translation happens is a big part of what gives the different languages their different capabilities. I will not go very deep into the subject, as it is to comprehensive for this thesis, but try to scratch the surface such that the different capabilities of the different languages becomes clear.

Firstly, before the translation happens, the program needs to be type checked. This consist of verifying that the variables are not set to unsupported types. For example, an array consisting of integers cannot at any point in the program be assigned to hold a string in one of its elements. There are two ways of type checking, the first is called static and the second is called dynamic. In a static language each variable needs to have a defined type beforehand and they are checked before the program is executed. We say that type checking happens before run-time. In dynamic languages the types of the variables does not need to be known before run-time and type correctness is checked at run-time, or in other words, continuously as the code is executed. Static languages are faster in the execution since it does not need to check for types as it is already done. You will, however, have to wait for the type checking to finish before the program can be executed. Dynamic languages are slower but the continuous type checking enables language designs that optimizes the coding process such that you can implement your program with less code. The first and most obvious difference from static languages is that you do not have to define what types each variable is. The type checking will find this out on its own at run-time. In addition it opens up for a feature called metaprogramming. Metaprogramming is programs that can take in other code as input and modify it such that implementing your code can be done more efficiently and faster. More specifically how this can be used will be discussed closer in \autoref{sec:Metaprogramming}.

The next difference between the languages is whether it is compiled or interpreted. A compiled language translates the source code to machine code before run-time. An interpreted language translates the code at run-time. It can be looked at as for each line of code it is first translated and then executed. Compiled languages are faster in the execution than an interpreted language. The reason for this is that when it translates all the code beforehand it can optimize the code that will be executed. You will, however, have to wait for the compiler to finish translating before the program can be executed. Hence, using an interpreted language can be faster when developing programs, as you do not have to recompile your entire program every time you have made a small change. There is also a third way to translate source code into machine code, called Just-in-time compilation(JIT compilation). JIT compiled languages is a combination of compiled and interpreted languages. It compiles blocks of the source code such that it can do optimizations like compiled code, but at the same time it does not need to compile the whole source code before it executes the program. In this way it behaves like an interpreted language but it will be faster as the code is compiled to machine code and not interpreted, but in most cases it will be slower than regular compiled languages. Disadvantages for JIT compiled languages is extra memory usage and that writing a JIT compiler is more difficult than other compilers. The latter does not affect the end user of the language.

For numerical applications we can separate the most commonly used languages into two groups. The first group is static and compiled languages like C and C++. These are languages that executes very fast but the time it takes to make the programs are longer. The second group are dynamic and interpreted languages. Such languages are for example MATLAB and Python and they are easier to use if you want to create numerical simulations, but they execute slower than C and C++. Julia is a dynamic, but compiled language. As the creators said in the blog post from 2012: Julia is supposed to have "... familiar mathematical notation like Matlab." be "... as  powerful  for  linear  algebra  as Matlab..." and at the same time be as fast as C. Summed up their goal has been to make a language that is as easy to use as an interpreted and dynamic language, but with the speed of a compiled and static language. Based on this description, Julia seems to be the perfect language for numerical simulations.

The process of creating a new programming language is however long. In 2009 the creators began the project of creating Julia and in the blog post \emph{\citep{juliaBlogRelease2012}} from 2012 they said "It’s not complete, but it’s time for a 1.0 release — the language we’ve created is called Julia". In a new blog post from August 8th 2018 \emph{\cite{juliaBlogReleaseV1.0}}, where they released the actual version 1.0 they admitted that they had jumped the gun a little with the mentioning of v1.0 in 2012, as it took more than six years before it actually happened. But after almost ten years of development v1.0 of the Julia language was released. The major consequence of a 1.0 release is that from this version and on, they guarantee backward compatibility. When they did not guarantee backward compatibility, code that worked on version, 0.1, 0.2 etc. would not necessarily run on newer versions. But from v1.0, all code that run on this version, will also run on future releases. This was a huge milestone for the Julia language. 

A consequence of the non backward compatibility is that when you search the internet for help in Julia, less than one year after the v1.0 release, you will end up finding solutions to your problem that no longer works. Hence as of now you need to be careful and check the date of the answers, and keep in mind that if it is from before v1.0 it might no longer work. This can at some times be frustrating, especially when you try to learn the language. However, now that there is backward compatibility for future releases, as time goes by, this problem will disappear as pre-v1.0 answers will eventually drown by post v1.0 answers.

Since Julia is an open source and free program to use, one of its strengths is that developers can contribute by creating useful programs that they share with all the other users. One example of this is the Integrated Development Environment (IDE), \cite{JunoIDE}. Juno is a program to help writing Julia code easier and is created by mainly two developers, Sebastian Pfitzner and Mike J. Innes. Juno gives the coder an environment where it is easy to run your Julia code, you get auto completion when writing your code, it has built in plotting panes to visualize results, and much more. The program is open source and free to use, and if you look at \cite{JunoGithub} there are many other contributors to the IDE than only Pfitzner and Innes. These are developers that have either found an error in the existing code or made a feature they wanted for the IDE. This shows the strength of the code being open source -- the community can contribute to the code database. This will help finishing improvements and error corrections to the code database quicker. This is why v1.0 of Julia was such a milestone, because as soon as Julia has guaranteed backward compatibility, there is a lot easier for developers to justify spending time to develop programs for Julia. This is because they now know the work they put in, will not be in vain, as the code will work on all future releases. 

\subsection{Metaprogramming in Julia}
\label{sec:Metaprogramming}
In the last year there have been published numerous projects that makes coding in Julia easier. A lot of these projects exploits that Julia is a dynamic language and that it has metaprogramming. In the blog post from \cite{juliaBlogRelease2012} the creators says that Julia shall contain "... true macros like Lisp...". Macros are functions in Julia that are using metaprogramming to modify your existing code to give some extra functionality. The macro functions are easily recognized by an "@" in front of the function name. To use a macro function on any function, you simply call the macro function before original function call, and the metaprogramming will handle the rest. I will now show three examples of macro functions in Julia that are very useful when creating a numerical simulations.
\subsubsection{Profiling}
The first macro function I want to show is the \texttt{@profiler} function. Profiling is an effective method to obtain overview of where the bottlenecks lie in a code when trying to optimize its performance. The method consist of taking snapshots of the code with small time intervals and for each snapshot we register what function we are at and the functions that have called this function. In this way we obtain a register of how many times we have observed that we have been in every function. This will not give a perfect overview of how much time we spend in each function, and we even risk not registering all functions we use. But as the time interval between the snapshots are small (e.g. every tenth microsecond), a function that is not registered will not be interesting to optimize as it already is very fast. 
\begin{figure}[H]
    \centering
    \includegraphics[width = \textwidth]{figures/profiling_screenshot.png}
    \caption{}
    \label{fig:profilingExample}
\end{figure}

\subsubsection{Debugger}
\subsubsection{Benchmarking}